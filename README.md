GESTURE RECOGNITION FOR CONTROLLING ELEMENTS OF THE SMART LAB
The complete task can be depicted as shown in the Figure below.
Note: Programming language: Python
Tasks 1,2 and 3 are interlinked. Likewise Tasks 3, 4 and 5 are also interlinked.
Task 1: There is an algorithm with me. We need to develop it programmatically.
Task 2: 250*4 = 1000 gestures has to be recorded.
Task 3: Completing the old algorithm and tuning the model
Task 4: Need to collaborate with other teams in order to develop the logic for recognize the positional
zone of the user in the smart lab.
Task 5: Need to develop a socket communication with the middleware so that the shades and the lights
can be controlled via commands.
The last task would be regression testing of the system.
Deadline: 6/7/2018 (Tentative) for development.
